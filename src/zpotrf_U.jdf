extern "C" %{
/*
 * Copyright (c) 2010-2022 The University of Tennessee and The University
 *                         of Tennessee Research Foundation.  All rights
 *                         reserved.
 * Copyright (c) 2013      Inria. All rights reserved.
 *
 * @precisions normal z -> s d c
 *
 */
#include "dplasmajdf.h"
#include "parsec/data_dist/matrix/matrix.h"

#if defined(DPLASMA_WITH_RECURSIVE)
#include "parsec/data_dist/matrix/subtile.h"
#include "parsec/recursive.h"
#endif

#if defined(DPLASMA_HAVE_CUDA)
#include <cublas_v2.h>
#include "potrf_cublas_utils.h"

#endif  /* defined(DPLASMA_HAVE_CUDA) */

/* Define the different shapes this JDF is using */
#define DEFAULT 0

/* Assume the functions on type & type_remote will return parsec_arena_datatype_t */
#define JDF2C_TYPE_ADT_NOT_INDEX

/* Include the functions to obtain the parsec_arena_datatype_t */
#include "dplasmajdf_lapack_dtt.h"
//#define FULL_CONVERSION
#ifdef FULL_CONVERSION
#define ADTT_READ(dM, loc, shape, layout) ADTT_DC(dM, loc, shape, layout)
#else
#define ADTT_READ(dM, loc, shape, layout) ADTT_DC(dM, loc, shape, LAPACK)
#endif

/* Note: with this approach to support LAPACK format and minimize
 * the number of tile conversions performed, it is critical to
 * determined the correct location on the matrix where the tile was
 * originated from.
 * Note that the LOC parameters do not correspond to the binding of the
 * task to the matrix (although sometimes they match). These parameters
 * correspond to the location were the datacopy was originate on the matrix (maybe
 * it was read on another task).
 * If there is no possibility to determine it (datacopy passed along multiple
 * tasks and that information is lost) the approach is to force a reshapping.
 *
 */

#include "zpotrf_U.h"

/*
 * Priorities used in this jdf:
 *      - potrf_zpotrf(k)    : (MT-k)**3
 *      - potrf_zherk(k,n)   : (MT-n)**3 + 3 * (n - k)
 *      - potrf_ztrsm(n,k)   : (MT-n)**3 + 3 * (n - k) * (2 * MT - k - n - 1)
 *      - potrf_zgemm(m,n,k) : (MT-n)**3 + 3 * (n - m) * (2 * MT - m - n - 3) + 6 * (n - k)
 *
 * So max priority is:
 *      (MT - PRI_CHANGE)**3 + 3 * MT * (2 * MT - PRI_CHANGE - 1) + 6 * MT  < (MT**3 + 6 MT**2 + 6 MT)
 *
 * WARNING: If mt is greater than 1200, we might get integer overflow.
 */

%}

/* Globals
 */
uplo       [type = dplasma_enum_t]
ddescA     [type = "dplasma_data_collection_t*"]
descA      [type = "parsec_tiled_matrix_t*" hidden = on default = "(((dplasma_data_collection_t*)ddescA)->dc_original)" aligned=ddescA]
INFO       [type = "int*"]

PRI_CHANGE [type = "int" hidden = on default = 0 ]
PRI_MAX    [type = "int" hidden = on default = "(descA->mt * ( 6 + descA->mt * ( 6 + descA->mt )))" ]
smallnb    [type = "int" hidden = on default = "descA->mb" ]

CuHandlesID   [type = "int" hidden = on default = -1 ]
POWorkspaceID [type = "int" hidden = on default = -1 ]

/**************************************************
 *               potrf_zpotrf                     *
 **************************************************/
potrf_zpotrf(k) [high_priority = on flops = inline_c %{ return FLOPS_ZPOTRF( CLEAN_NB(descA, k) ); %}]

// Execution space
k = 0 .. descA->nt-1

loc_T = %{ return LOC(descA, k, k); %}

// Parallel partitioning
:descA(k, k)

// Parameters
RW T <- (k == 0) ? ddescA(k, k)            [ type        = %{ return ADTT_READ(ddescA, loc_T, DEFAULT, TILED); %}
                                             type_data   = %{ return ADTT_READ(ddescA, loc_T, DEFAULT, LAPACK); %} ]
     <- (k != 0) ? T potrf_zherk(k-1, k)   [ type_remote = %{ return ADTT_DC(ddescA, loc_T, DEFAULT, TILED); %} ]
     -> T potrf_ztrsm(k, k+1..descA->nt-1) /* dep OUT: rely on datacopy dtt for sending */
     -> ddescA(k, k)                       [ type        = %{ return ADTT_CP(_f_T, ddescA, loc_T, DEFAULT); %}
                                             type_data   = %{ return ADTT_DC(ddescA, loc_T, DEFAULT, LAPACK); %} ]

; (k >= (descA->nt - PRI_CHANGE)) ? (descA->nt - k) * (descA->nt - k) * (descA->nt - k) : PRI_MAX

BODY [type=RECURSIVE]
{
    int tempkn = k == descA->nt-1 ? descA->n - k*descA->nb : descA->nb;
    int iinfo = 0;

    if (tempkn > smallnb)
    {
        subtile_desc_t *small_descT;
        parsec_taskpool_t *parsec_zpotrf;

        small_descT = subtile_desc_create( descA, k, k,
                                           smallnb, smallnb, 0, 0, tempkn, tempkn );
        small_descT->mat = T;

        parsec_zpotrf = dplasma_zpotrf_New(uplo, (parsec_tiled_matrix_t *)small_descT, &iinfo );

        parsec_recursivecall((parsec_task_t*)this_task,
                             parsec_zpotrf, dplasma_zpotrf_Destruct,
                             1, small_descT);

        return PARSEC_HOOK_RETURN_ASYNC;
    }
    else
        /* Go for the sequential CPU version */
        return PARSEC_HOOK_RETURN_NEXT;
}
END

BODY [type=CUDA
      dyld=cusolverDnZpotrf dyldtype=cublas_zpotrf_v2_t
      weigth=k]
{
    int tempkn = k == descA->nt-1 ? descA->n - k*descA->nb : descA->nb;
    int ldak = LDA(ddescA, T);

    cusolverStatus_t status;
    cublasFillMode_t cublas_uplo;
    dplasma_potrf_workspace_t *wp;
    cuDoubleComplex *workspace;
    int             *d_iinfo;
    dplasma_cuda_handles_t *handles;

    if( PlasmaLower == uplo )
        cublas_uplo = CUBLAS_FILL_MODE_LOWER;
    if( PlasmaUpper == uplo )
        cublas_uplo = CUBLAS_FILL_MODE_UPPER;

    handles = parsec_info_get(&gpu_stream->infos, CuHandlesID);
    assert(NULL != handles);
    wp = parsec_info_get(&gpu_device->super.infos, POWorkspaceID);
    assert(NULL != wp);

    workspace = (cuDoubleComplex*)wp->tmpmem;
    d_iinfo   = (int*)(wp->tmpmem + wp->lwork * sizeof(cuDoubleComplex));

    status = parsec_body.dyld_fn( handles->cusolverDn_handle, cublas_uplo, tempkn, T, ldak, workspace, wp->lwork, d_iinfo);
    PARSEC_CUDA_CHECK_ERROR( "cublasZpotrf_v2 ", status,
                            {return -1;} );
}
END

BODY
{
    int tempkn = k == descA->nt-1 ? descA->n - k*descA->nb : descA->nb;

    int iinfo = 0;
    int ldak = LDA(ddescA, T);

    CORE_zpotrf(uplo, tempkn, T, ldak, &iinfo );

    if( iinfo != 0 && *INFO == 0 )
        *INFO = k*descA->nb+iinfo; /* Should return here */

    printlog("CORE_zpotrf( %d )\n\t( %s, %d, A(%d,%d)[%p], %d) return info = %d\n",
             k,
             &dplasma_lapack_const(uplo), tempkn, k, k, T, ldak, iinfo );
}
END


/**************************************************
 *               potrf_ztrsm                      *
 **************************************************/
potrf_ztrsm(k, n) [high_priority = on flops = inline_c %{ return FLOPS_ZTRSM(PlasmaLeft, descA->mb, CLEAN_NB(descA, n)); %}]

// Execution space
k = 0   .. descA->nt-2
n = k+1 .. descA->nt-1

loc_T = %{ return LOC(descA, k, k); %}
loc_C = %{ return LOC(descA, k, n); %}

// Parallel partitioning
: descA(k, n)

// Parameters
READ  T <- T potrf_zpotrf(k)                     [ type_remote = %{ return ADTT_DC(ddescA, loc_T, DEFAULT, TILED); %} ]
RW    C <- (k == 0) ? ddescA(k, n)               [ type        = %{ return ADTT_READ(ddescA, loc_C, DEFAULT, TILED); %}
                                                   type_data   = %{ return ADTT_READ(ddescA, loc_C, DEFAULT, LAPACK); %} ]
        <- (k != 0) ? C potrf_zgemm(k, n, k-1)   [ type_remote = %{ return ADTT_DC(ddescA, loc_C, DEFAULT, TILED); %} ]
        -> A potrf_zherk(k, n)                   /* dep OUT: rely on datacopy dtt for sending */
        -> A potrf_zgemm(n, n+1..descA->nt-1, k) /* dep OUT: rely on datacopy dtt for sending */
        -> B potrf_zgemm(k+1..n-1, n, k)         /* dep OUT: rely on datacopy dtt for sending */
        -> ddescA(k, n)                         [ type        = %{ return ADTT_CP(_f_C, ddescA, loc_C, DEFAULT); %}
                                                  type_data   = %{ return ADTT_DC(ddescA, loc_C, DEFAULT, LAPACK); %} ]

; (n >= (descA->nt - PRI_CHANGE)) ? (descA->nt - n) * (descA->nt - n) * (descA->nt - n) + 3 * ((2 * descA->nt) - k - n - 1) * (n - k) : PRI_MAX

        BODY [type=CUDA
              dyld=cublasZtrsm_v2 dyldtype=cublas_ztrsm_v2_t
              weight=(k+n)]
{
    int tempnn = n == descA->nt - 1 ? descA->n - n * descA->nb : descA->nb;
    int ldak_T = LDA(ddescA, T);
    int ldak_C = LDA(ddescA, C);
    dplasma_cuda_handles_t *handles;
#if defined(PRECISION_z) || defined(PRECISION_c)
    cuDoubleComplex zone  = make_cuDoubleComplex( 1., 0.);
#else
    double zone = 1.;
#endif

    cublasStatus_t status;
    handles = parsec_info_get(&gpu_stream->infos, CuHandlesID);
    assert(NULL != handles);
    status = parsec_body.dyld_fn(handles->cublas_handle,
                                 CUBLAS_SIDE_LEFT, CUBLAS_FILL_MODE_UPPER,
                                 CUBLAS_OP_C, CUBLAS_DIAG_NON_UNIT,
                                 descA->mb, tempnn,
                                 &zone, T, ldak_T, C, ldak_C);
    PARSEC_CUDA_CHECK_ERROR( "cublasZtrsm_v2 ", status,
                            {return -1;} );
}
END

BODY [type=RECURSIVE]
{
    int tempnn = n == descA->nt-1 ? descA->n - n * descA->nb : descA->nb;

    if ( (tempnn > smallnb) || (descA->mb > smallnb) )
    {
        subtile_desc_t *small_descT;
        subtile_desc_t *small_descC;
        parsec_taskpool_t* parsec_ztrsm;


        small_descT = subtile_desc_create( descA, k, k,
                                           smallnb, smallnb, 0, 0, descA->mb, descA->mb );
        small_descT->mat = T;

        small_descC = subtile_desc_create( descA, k, n,
                                           smallnb, smallnb, 0, 0, descA->mb, tempnn );
        small_descC->mat = C;

        parsec_ztrsm = dplasma_ztrsm_New(dplasmaLeft, dplasmaUpper,
                                        dplasmaConjTrans, dplasmaNonUnit,
                                        (dplasma_complex64_t)1.0,
                                        (parsec_tiled_matrix_t *)small_descT,
                                        (parsec_tiled_matrix_t *)small_descC );

        parsec_recursivecall((parsec_task_t*)this_task,
                             parsec_ztrsm, dplasma_ztrsm_Destruct,
                             2, small_descT, small_descC );

        return PARSEC_HOOK_RETURN_ASYNC;
    }
    else
        /* Go for the sequential CPU version */
        return PARSEC_HOOK_RETURN_NEXT;
}
END

BODY
{
    int tempnn = n == descA->nt-1 ? descA->n - n * descA->nb : descA->nb;
    int ldak_T = LDA(ddescA, T);
    int ldak_C = LDA(ddescA, C);

    CORE_ztrsm(dplasmaLeft, dplasmaUpper, dplasmaConjTrans, dplasmaNonUnit,
               descA->mb, tempnn,
               (dplasma_complex64_t)1.0, T /*A(k, k)*/, ldak_T,
                                         C /*A(k, n)*/, ldak_C);

    printlog("CORE_ztrsm( %d, %d )\n\t( %s, %s, %s, %s, %d, %d, %f, A(%d,%d)[%p], %d,  A(%d,%d)[%p], %d)\n",
             k, n,
             &dplasma_lapack_const( dplasmaLeft ), &dplasma_lapack_const( dplasmaUpper ),
             &dplasma_lapack_const( dplasmaConjTrans ), &dplasma_lapack_const( dplasmaNonUnit ),
             descA->mb, tempnn,
             1.0, k, k, T, ldak_T,
                  k, n, C, ldak_C);
}
END


/**************************************************
 *               potrf_zherk                      *
 **************************************************/
potrf_zherk(k, n) [high_priority = on flops = inline_c %{ return FLOPS_ZHERK(CLEAN_NB(descA, n), descA->mb); %}]

// Execution space
k = 0   .. descA->nt-2
n = k+1 .. descA->nt-1

loc_A = %{ return LOC(descA, k, n); %}
loc_T = %{ return LOC(descA, n, n); %}

// Parallel partitioning
: descA(n, n)

//Parameters

READ  A <- C potrf_ztrsm(k, n)                [ type_remote = %{ return ADTT_DC(ddescA, loc_A, DEFAULT, TILED); %} ]
RW    T <- (k == 0)   ? ddescA(n, n)          [ type        = %{ return ADTT_READ(ddescA, loc_T, DEFAULT, TILED); %}
                                                type_data   = %{ return ADTT_READ(ddescA, loc_T, DEFAULT, LAPACK); %} ]
        <- (k != 0)   ? T potrf_zherk(k-1, n) [ type_remote = %{ return ADTT_DC(ddescA, loc_T, DEFAULT, TILED); %} ]
        -> (n == k+1) ? T potrf_zpotrf(n) : T potrf_zherk(k+1, n) /* dep OUT: rely on datacopy dtt for sending */

; (n >= (descA->nt - PRI_CHANGE)) ? (descA->nt - n) * (descA->nt - n) * (descA->nt - n) + 3 * (n - k) : PRI_MAX

BODY [type=CUDA
      dyld=cublasZherk_v2 dyldtype=cublas_zherk_v2_t
      weight=(k+n)]
{
    int tempnn = n == descA->nt-1 ? descA->n - n*descA->nb : descA->nb;
    int ldak = LDA(ddescA, A);
    int ldan = LDA(ddescA, T);
    dplasma_cuda_handles_t *handles;
    double zone  =  1.;
    double mzone = -1.;
    cublasStatus_t status;

    handles = parsec_info_get(&gpu_stream->infos, CuHandlesID);
    assert(NULL != handles);
    status = parsec_body.dyld_fn( handles->cublas_handle,
                                  CUBLAS_FILL_MODE_UPPER, CUBLAS_OP_C,
                                  tempnn, descA->mb,
                                  &mzone, A, ldak,
                                  &zone, T, ldan);

    PARSEC_CUDA_CHECK_ERROR( "cublasZherk_v2 ", status,
                            {return -1;} );
}
END

BODY [type=RECURSIVE]
{
    int tempnn = n == descA->nt-1 ? descA->n - n*descA->nb : descA->nb;

    if ( (tempnn > smallnb) || (descA->mb > smallnb) )
    {
        subtile_desc_t *small_descT;
        subtile_desc_t *small_descA;
        parsec_taskpool_t* parsec_zherk;

        small_descT = subtile_desc_create( descA, n, n,
                                           smallnb, smallnb, 0, 0, tempnn, tempnn );
        small_descT->mat = T;

        small_descA = subtile_desc_create( descA, k, n,
                                           smallnb, smallnb, 0, 0, descA->mb, tempnn );
        small_descA->mat = A;

        parsec_zherk = dplasma_zherk_New( dplasmaUpper, dplasmaConjTrans,
                                         (double)-1.0, (parsec_tiled_matrix_t*) small_descA,
                                         (double)1.0,  (parsec_tiled_matrix_t*) small_descT);

        parsec_recursivecall((parsec_task_t*)this_task,
                             parsec_zherk, dplasma_zherk_Destruct,
                             2, small_descA, small_descT);
        return PARSEC_HOOK_RETURN_ASYNC;
    }
    else
        /* Go for the sequential CPU version */
        return PARSEC_HOOK_RETURN_NEXT;
}
END

BODY
{
    int tempnn = n == descA->nt-1 ? descA->n - n*descA->nb : descA->nb;
    int ldak = LDA(ddescA, A);
    int ldan = LDA(ddescA, T);

    CORE_zherk(dplasmaUpper, dplasmaConjTrans,
               tempnn, descA->mb,
               (double)-1.0, A /*A(k, n)*/, ldak,
               (double) 1.0, T /*A(n, n)*/, ldan);

    printlog("CORE_zherk( %d, %d )\n\t( %s, %s, %d, %d, %f, A(%d,%d)[%p], %d, %f, A(%d,%d)[%p], %d)\n",
             k, n,
             &dplasma_lapack_const( dplasmaUpper ), &dplasma_lapack_const( dplasmaConjTrans ),
             tempnn, descA->mb,
             -1.0, k, n, A, ldak,
              1.0, n, n, T, ldan);
}
END

/**************************************************
 *               potrf_zgemm                      *
 **************************************************/
// Name
potrf_zgemm(m, n, k) [ flops = inline_c %{ return FLOPS_ZGEMM(descA->mb, CLEAN_NB(descA, n), descA->nb); %}]

// Execution space
k = 0   .. descA->mt-3
m = k+1 .. descA->mt-1
n = m+1 .. descA->nt-1

loc_A = %{ return LOC(descA, k, m); %}
loc_B = %{ return LOC(descA, k, n); %}
loc_C = %{ return LOC(descA, m, n); %}

// Parallel partitioning
: descA(m, n)

// Parameters
READ  A <- C potrf_ztrsm(k, m)                   [ type_remote = %{ return ADTT_DC(ddescA, loc_A, DEFAULT, TILED); %} ]
READ  B <- C potrf_ztrsm(k, n)                   [ type_remote = %{ return ADTT_DC(ddescA, loc_B, DEFAULT, TILED); %} ]
RW    C <- (k == 0)   ? ddescA(m, n)             [ type        = %{ return ADTT_READ(ddescA, loc_C, DEFAULT, TILED); %}
                                                   type_data   = %{ return ADTT_READ(ddescA, loc_C, DEFAULT, LAPACK); %} ]
        <- (k != 0)   ? C potrf_zgemm(m, n, k-1) [ type_remote = %{ return ADTT_DC(ddescA, loc_C, DEFAULT, TILED); %} ]
        -> (m == k+1) ? C potrf_ztrsm(m, n) : C potrf_zgemm(m, n, k+1) /* dep OUT: rely on datacopy dtt for sending */

; (n >= (descA->nt - PRI_CHANGE)) ? (descA->nt - n) * (descA->nt - n) * (descA->nt - n) + 3 * ((2 * descA->nt) - m - n - 3) * (n - m) + 6 * (n - k) : PRI_MAX

BODY [type=CUDA
      dyld=cublasZgemm_v2 dyldtype=cublas_zgemm_v2_t
      weight=(m+1-k)
      A.size=%{ return descA->mb*descA->nb*parsec_datadist_getsizeoftype(descA->mtype);%}
      B.size=%{ return descA->mb*descA->nb*parsec_datadist_getsizeoftype(descA->mtype);%}
      C.size=%{ return descA->mb*descA->nb*parsec_datadist_getsizeoftype(descA->mtype);%}
      A.dc=ddescA B.dc=ddescA C.dc=ddescA
      stage_in=stage_in_lapack
      stage_out=stage_out_lapack]
{
#if defined(PRECISION_z) || defined(PRECISION_c)
    cuDoubleComplex zone  = make_cuDoubleComplex( 1., 0.);
    cuDoubleComplex mzone = make_cuDoubleComplex(-1., 0.);
#else
    double zone  =  1.;
    double mzone = -1.;
#endif

    int tempnn = n == descA->nt-1 ? descA->n - n * descA->nb : descA->nb;
    int ldak_A = LDA(ddescA, A);
    int ldak_B = LDA(ddescA, B);
    int ldam_C = LDA(ddescA, C);

    cublasStatus_t status;
    dplasma_cuda_handles_t *handles;

    assert( ldak_A <= descA->mb );
    assert( ldak_B <= descA->mb );
    assert( ldam_C <= descA->mb );

    handles = parsec_info_get(&gpu_stream->infos, CuHandlesID);
    assert(NULL != handles);

    cublasSetKernelStream( parsec_body.stream );
    status = parsec_body.dyld_fn( handles->cublas_handle,
                                  CUBLAS_OP_C, CUBLAS_OP_N,
                                  descA->mb, tempnn, descA->nb,
                                  &mzone, (cuDoubleComplex*)A, ldak_A,
                                          (cuDoubleComplex*)B, ldak_B,
                                  &zone,  (cuDoubleComplex*)C, ldam_C);
    PARSEC_CUDA_CHECK_ERROR( "cublasZgemm_v2 ", status,
                            {return -1;} );

    printlogcuda("CUDA_zgemm( %d, %d, %d )\n\t( %s, %s, %d, %d, %d, %f, A(%d,%d)[%p], %d, A(%d,%d)[%p], %d, %f, A(%d,%d)[%p], %d)\n",
                 m, n, k,
                 &dplasma_lapack_const( dplasmaConjTrans ),  &dplasma_lapack_const( dplasmaNoTrans ),
                 descA->mb, tempnn, descA->nb,
                 -1.0, k, m, A, ldak_A,
                       k, n, B, ldak_B,
                  1.0, m, n, C, ldam_C);
}
END

BODY [type=RECURSIVE]
{
    int tempnn = n == descA->nt-1 ? descA->n - n * descA->nb : descA->nb;

    if ( (tempnn > smallnb) || (descA->mb > smallnb) )
    {
        subtile_desc_t *small_descA;
        subtile_desc_t *small_descB;
        subtile_desc_t *small_descC;
        parsec_taskpool_t *parsec_zgemm;

        small_descA = subtile_desc_create( descA, k, m,
                                           smallnb, smallnb, 0, 0, descA->mb, descA->nb );
        small_descA->mat = A;

        small_descB = subtile_desc_create( descA, k, n,
                                           smallnb, smallnb, 0, 0, descA->mb, tempnn );
        small_descB->mat = B;

        small_descC = subtile_desc_create( descA, m, n,
                                           smallnb, smallnb, 0, 0, descA->mb, tempnn );
        small_descC->mat = C;

        parsec_zgemm = dplasma_zgemm_New(dplasmaConjTrans, dplasmaNoTrans,
                                        (dplasma_complex64_t)-1.0,
                                        (parsec_tiled_matrix_t *)small_descA,
                                        (parsec_tiled_matrix_t *)small_descB,
                                        (dplasma_complex64_t) 1.0,
                                        (parsec_tiled_matrix_t *)small_descC);

        parsec_recursivecall((parsec_task_t*)this_task,
                             parsec_zgemm, dplasma_zgemm_Destruct,
                             3, small_descA, small_descB, small_descC );

        return PARSEC_HOOK_RETURN_ASYNC;
    }
    else
        /* Go to CPU sequential kernel */
        return PARSEC_HOOK_RETURN_NEXT;
}
END

BODY
{
    int tempnn = n == descA->nt-1 ? descA->n - n * descA->nb : descA->nb;
    int ldak_A = LDA(ddescA, A);
    int ldak_B = LDA(ddescA, B);
    int ldam_C = LDA(ddescA, C);

    CORE_zgemm(dplasmaConjTrans, dplasmaNoTrans,
               descA->mb, tempnn, descA->nb,
               (dplasma_complex64_t)-1.0, A /*A(k, m)*/, ldak_A,
                                          B /*A(k, n)*/, ldak_B,
               (dplasma_complex64_t) 1.0, C /*A(m, n)*/, ldam_C);

    printlog("CORE_zgemm( %d, %d, %d )\n\t( %s, %s, %d, %d, %d, %f, A(%d,%d)[%p], %d, A(%d,%d)[%p], %d, %f, A(%d,%d)[%p], %d)\n",
             m, n, k,
             &dplasma_lapack_const( dplasmaConjTrans ),  &dplasma_lapack_const( dplasmaNoTrans ),
             descA->mb, tempnn, descA->nb,
             -1.0, k, m, A, ldak_A,
                   k, n, B, ldak_B,
              1.0, m, n, C, ldam_C);
}
END
