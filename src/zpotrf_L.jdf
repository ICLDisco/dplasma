extern "C" %{
/*
 * Copyright (c) 2010-2024 The University of Tennessee and The University
 *                         of Tennessee Research Foundation.  All rights
 *                         reserved.
 * Copyright (c) 2013      Inria. All rights reserved.
 *
 * @precisions normal z -> s d c
 *
 */
#include "dplasma/config.h"
#include "dplasmajdf.h"
#include "parsec/data_dist/matrix/matrix.h"
#include "potrf_gpu_workspaces.h"

#if defined(PARSEC_HAVE_DEV_RECURSIVE_SUPPORT)
#include "parsec/data_dist/matrix/subtile.h"
#include "parsec/recursive.h"
static void zpotrf_recursive_cb(parsec_taskpool_t* tp, const parsec_recursive_callback_t* data);
static void zgemm_recursive_cb(parsec_taskpool_t* tp, const parsec_recursive_callback_t* data);
static void zherk_recursive_cb(parsec_taskpool_t* tp, const parsec_recursive_callback_t* data);
static void ztrsm_recursive_cb(parsec_taskpool_t* tp, const parsec_recursive_callback_t* data);
#endif /* PARSEC_HAVE_DEV_RECURSIVE_SUPPORT */

/* Define the different shapes this JDF is using */
#define DEFAULT 0

/* Assume the functions on type & type_remote will return parsec_arena_datatype_t */
#define JDF2C_TYPE_ADT_NOT_INDEX

/* Include the functions to obtain the parsec_arena_datatype_t */
#include "dplasmajdf_lapack_dtt.h"
//#define FULL_CONVERSION
#ifdef FULL_CONVERSION
#define ADTT_READ(dM, loc, shape, layout) ADTT_DC(dM, loc, shape, layout)
#else
#define ADTT_READ(dM, loc, shape, layout) ADTT_DC(dM, loc, shape, LAPACK)
#endif

/* Note: with this approach to support LAPACK format and minimize
 * the number of tile conversions performed, it is critical to
 * determined the correct location on the matrix where the tile was
 * originated from.
 * Note that the LOC parameters do not correspond to the binding of the
 * task to the matrix (although sometimes they match). These parameters
 * correspond to the location were the datacopy was originate on the matrix (maybe
 * it was read on another task).
 * If there is no possibility to determine it (datacopy passed along multiple
 * tasks and that information is lost) the approach is to force a reshapping.
 *
 */

/*
 * Priorities used in this jdf:
 *      - potrf_zpotrf(k)    : (MT-k)**3
 *      - potrf_zherk(k,m)   : (MT-m)**3 + 3 * (m - k)
 *      - potrf_ztrsm(m,k)   : (MT-m)**3 + 3 * (m - k) * (2 * MT - k - m - 1)
 *      - potrf_zgemm(m,n,k) : (MT-m)**3 + 3 * (m - n) * (2 * MT - m - n - 3) + 6 * (m - k)
 *
 * So max priority is:
 *      (MT - PRI_CHANGE)**3 + 3 * MT * (2 * MT - PRI_CHANGE - 1) + 6 * MT  < (MT**3 + 6 MT**2 + 6 MT)
 *
 * WARNING: If mt is greater than 1200, we might get integer overflow.
 */

static int64_t zpotrf_time_estimate(const parsec_task_t *task, parsec_device_module_t *dev);
static int64_t ztrsm_time_estimate(const parsec_task_t *task, parsec_device_module_t *dev);
static int64_t zherk_time_estimate(const parsec_task_t *task, parsec_device_module_t *dev);
static int64_t zgemm_time_estimate(const parsec_task_t *task, parsec_device_module_t *dev);
%}

/* Globals
 */
uplo       [type = dplasma_enum_t]
ddescA     [type = "dplasma_data_collection_t*"]
descA      [type = "parsec_tiled_matrix_t*" hidden = on default = "((dplasma_data_collection_t*)ddescA)->dc_original" aligned=ddescA]
INFO       [type = "int*"]

PRI_CHANGE    [type = "int" hidden = on default = 0 ]
PRI_MAX       [type = "int" hidden = on default = "(descA->mt * ( 6 + descA->mt * ( 6 + descA->mt )))" ]
smallnb       [type = "int" hidden = on default = "descA->mb" ]

cuda_handles_infokey    [type = "int" hidden = on default = -1 ]
cuda_workspaces_infokey [type = "int" hidden = on default = -1 ]
hip_handles_infokey     [type = "int" hidden = on default = -1 ]
hip_workspaces_infokey  [type = "int" hidden = on default = -1 ]

/**************************************************
 *               potrf_zpotrf                     *
 **************************************************/
potrf_zpotrf(k) [high_priority = on
                 flops = inline_c %{ return FLOPS_ZPOTRF( CLEAN_MB(descA, k) ); %}
                 time_estimate = zpotrf_time_estimate]

// Execution space
k = 0 .. descA->mt-1

// Locals
info = 0  /* For the info in the case of recursive calls */
loc_T = %{ return LOC(descA, k, k); %}

// Parallel partitioning
:descA(k, k)

// Parameters

RW T <- (k == 0) ? ddescA(k, k)            [ type        = %{ return ADTT_READ(ddescA, loc_T, DEFAULT, TILED); %}
                                             type_data   = %{ return ADTT_READ(ddescA, loc_T, DEFAULT, LAPACK); %} ]
     <- (k != 0) ? T potrf_zherk(k-1, k)   [ type_remote = %{ return ADTT_DC(ddescA, loc_T, DEFAULT, TILED); %} ]
     -> T potrf_ztrsm(k+1..descA->mt-1, k) /* dep OUT: rely on datacopy dtt for sending */
     -> ddescA(k, k)                       [ type        = %{ return ADTT_CP(_f_T, ddescA, loc_T, DEFAULT); %}
                                             type_data   = %{ return ADTT_DC(ddescA, loc_T, DEFAULT, LAPACK); %} ]

; (k >= (descA->mt - PRI_CHANGE)) ? (descA->mt - k) * (descA->mt - k) * (descA->mt - k) : PRI_MAX

BODY [type=CUDA]
{
    int tempkm = k == descA->mt-1 ? descA->m - k*descA->mb : descA->mb;
    int ldak = LDA(ddescA, T);

    cusolverStatus_t status;
    cublasFillMode_t cublas_uplo;
    dplasma_potrf_gpu_workspaces_t *wp;
    cuDoubleComplex *workspace;
    int             *d_iinfo;
    dplasma_cuda_handles_t *handles;

    if( PlasmaLower == uplo )
        cublas_uplo = CUBLAS_FILL_MODE_LOWER;
    if( PlasmaUpper == uplo )
        cublas_uplo = CUBLAS_FILL_MODE_UPPER;

    handles = parsec_info_get(&gpu_stream->infos, cuda_handles_infokey);
    assert(NULL != handles);
    wp = parsec_info_get(&gpu_device->super.infos, cuda_workspaces_infokey);
    assert(NULL != wp);

    workspace = (cuDoubleComplex*)wp->tmpmem;
    d_iinfo   = (int*)(wp->tmpmem + wp->lwork * sizeof(cuDoubleComplex));

    status = cusolverDnZpotrf( handles->cusolverDn_handle, cublas_uplo, tempkm, T, ldak, workspace, wp->lwork, d_iinfo);
    PARSEC_CUDA_CHECK_ERROR( "cublasZpotrf_v2 ", status, {return PARSEC_HOOK_RETURN_ERROR;} );
}
END

BODY [type=HIP]
{
    int tempkm = k == descA->mt-1 ? descA->m - k*descA->mb : descA->mb;
    int ldak = LDA(ddescA, T);

    rocblas_status status;
    rocblas_fill rocblas_uplo;
    dplasma_potrf_gpu_workspaces_t *wp;
    int *d_iinfo;
    dplasma_hip_handles_t *handles;

    if( PlasmaLower == uplo )
        rocblas_uplo = rocblas_fill_lower;
    if( PlasmaUpper == uplo )
        rocblas_uplo = rocblas_fill_upper;

    handles = parsec_info_get(&gpu_stream->infos, hip_handles_infokey);
    assert(NULL != handles);
    wp = parsec_info_get(&gpu_device->super.infos, hip_workspaces_infokey);
    assert(NULL != wp);

    d_iinfo = (int*)wp->tmpmem;

    status = rocsolver_zpotrf( handles->hipblas_handle, rocblas_uplo, tempkm, T, ldak, d_iinfo);
    DPLASMA_ROCBLAS_CHECK_ERROR("rocsolver_zpotrf", status, {return PARSEC_HOOK_RETURN_ERROR;});
}
END

BODY [type=RECURSIVE]
{
    int tempkm = k == descA->mt-1 ? descA->m - k*descA->mb : descA->mb;

    if (tempkm > smallnb)
    {
        subtile_desc_t *small_descT;
        parsec_taskpool_t *parsec_zpotrf;

        small_descT = subtile_desc_create( descA, k, k,
                                           smallnb, smallnb, 0, 0, tempkm, tempkm );
        small_descT->mat = T;

        parsec_zpotrf = dplasma_zpotrf_New(uplo, (parsec_tiled_matrix_t *)small_descT, (int*)&info );

        parsec_recursivecall((parsec_task_t*)this_task,
                             parsec_zpotrf, zpotrf_recursive_cb,
                             1, small_descT);

        return PARSEC_HOOK_RETURN_ASYNC;
    }
    /* Go for the sequential CPU version */
    return PARSEC_HOOK_RETURN_NEXT;
}
END

BODY
{
    int tempkm = k == descA->mt-1 ? descA->m - k*descA->mb : descA->mb;
    int iinfo = 0;
    int ldak = LDA(ddescA, T);

    CORE_zpotrf( uplo, tempkm, T, ldak, &iinfo );
    if ( iinfo != 0 && *INFO == 0 )
            *INFO = k*descA->mb+iinfo; /* Should return here */

    printlog("CORE_zpotrf( %d )\n\t( %s, %d, A(%d,%d)[%p], ldak %d) return info = %d\n",
             k,
             &dplasma_lapack_const(uplo), tempkm, k, k, T, ldak, iinfo );
}
END


/**************************************************
 *               potrf_ztrsm                      *
 **************************************************/
potrf_ztrsm(m, k) [high_priority = on
                   flops = inline_c %{ return FLOPS_ZTRSM(PlasmaRight, CLEAN_MB(descA, m), descA->nb); %}
                   time_estimate = ztrsm_time_estimate]

// Execution space
m = 1 .. descA->mt-1
k = 0 .. m-1

loc_T = %{ return LOC(descA, k, k); %}
loc_C = %{ return LOC(descA, m, k); %}

// Parallel partitioning
: descA(m, k)

// Parameters
READ  T <- T potrf_zpotrf(k)                     [ type_remote = %{ return ADTT_DC(ddescA, loc_T, DEFAULT, TILED); %} ]
RW    C <- (k == 0) ? ddescA(m, k)               [ type        = %{ return ADTT_READ(ddescA, loc_C, DEFAULT, TILED); %}
                                                   type_data   = %{ return ADTT_READ(ddescA, loc_C, DEFAULT, LAPACK); %} ]
        <- (k != 0) ? C potrf_zgemm(m, k, k-1)   [ type_remote = %{ return ADTT_DC(ddescA, loc_C, DEFAULT, TILED); %} ]
        -> A potrf_zherk(k, m)                   /* dep OUT: rely on datacopy dtt for sending */
        -> A potrf_zgemm(m, k+1..m-1, k)         /* dep OUT: rely on datacopy dtt for sending */
        -> B potrf_zgemm(m+1..descA->mt-1, m, k) /* dep OUT: rely on datacopy dtt for sending */
        -> ddescA(m, k)                          [ type        = %{ return ADTT_CP(_f_C, ddescA, loc_C, DEFAULT); %}
                                                   type_data   = %{ return ADTT_DC(ddescA, loc_C, DEFAULT, LAPACK); %} ]

; (m >= (descA->mt - PRI_CHANGE)) ? (descA->mt - m) * (descA->mt - m) * (descA->mt - m) + 3 * ((2 * descA->mt) - k - m - 1) * (m - k) : PRI_MAX

BODY [type=CUDA]
{
    int tempmm = m == descA->mt-1 ? descA->m - m * descA->mb : descA->mb;
    int ldak = LDA(ddescA, T);
    int ldam = LDA(ddescA, C);
    dplasma_cuda_handles_t *handles;
#if defined(PRECISION_z) || defined(PRECISION_c)
    cuDoubleComplex zone  = make_cuDoubleComplex( 1., 0.);
#else
    double zone = 1.;
#endif
    cublasStatus_t status;
    handles = parsec_info_get(&gpu_stream->infos, cuda_handles_infokey);
    assert(NULL != handles);
    cublasSetStream( handles->cublas_handle, parsec_body.stream );
    status = cublasZtrsm_v2(handles->cublas_handle,
                            CUBLAS_SIDE_RIGHT, CUBLAS_FILL_MODE_LOWER,
                            CUBLAS_OP_C, CUBLAS_DIAG_NON_UNIT,
                            tempmm, descA->nb,
                            &zone, T, ldak, C, ldam);
    PARSEC_CUDA_CHECK_ERROR( "cublasZtrsm_v2 ", status, {return PARSEC_HOOK_RETURN_ERROR;} );
}
END

BODY [type=HIP]
{
    int tempmm = m == descA->mt-1 ? descA->m - m * descA->mb : descA->mb;
    int ldak = LDA(ddescA, T);
    int ldam = LDA(ddescA, C);
    dplasma_hip_handles_t *handles;
#if defined(PRECISION_z) || defined(PRECISION_c)
    hipblasDoubleComplex zone  = { 1., 0. };
#else
    double zone = 1.;
#endif
    hipblasStatus_t status;
    handles = parsec_info_get(&gpu_stream->infos, hip_handles_infokey);
    assert(NULL != handles);
    status = hipblasZtrsm(handles->hipblas_handle,
                                 HIPBLAS_SIDE_RIGHT, HIPBLAS_FILL_MODE_LOWER,
                                 HIPBLAS_OP_C, HIPBLAS_DIAG_NON_UNIT,
                                 tempmm, descA->nb,
                                 &zone, T, ldak, C, ldam);
    DPLASMA_HIPBLAS_CHECK_ERROR("hipblasZtrsm", status, {return PARSEC_HOOK_RETURN_ERROR;});
}
END

BODY [type=RECURSIVE]
{
    int tempmm = m == descA->mt-1 ? descA->m - m * descA->mb : descA->mb;

    if ( (tempmm > smallnb) || (descA->nb > smallnb) )
    {
        subtile_desc_t *small_descT;
        subtile_desc_t *small_descC;
        parsec_taskpool_t* parsec_ztrsm;


        small_descT = subtile_desc_create( descA, k, k,
                                           smallnb, smallnb, 0, 0, descA->nb, descA->nb );
        small_descT->mat = T;

        small_descC = subtile_desc_create( descA, m, k,
                                           smallnb, smallnb, 0, 0, tempmm, descA->nb );
        small_descC->mat = C;

        parsec_ztrsm = dplasma_ztrsm_New(dplasmaRight, dplasmaLower,
                                        dplasmaConjTrans, dplasmaNonUnit,
                                        (dplasma_complex64_t)1.0,
                                        (parsec_tiled_matrix_t *)small_descT,
                                        (parsec_tiled_matrix_t *)small_descC );

        parsec_recursivecall((parsec_task_t*)this_task,
                             parsec_ztrsm, ztrsm_recursive_cb,
                             2, small_descT, small_descC );

        return PARSEC_HOOK_RETURN_ASYNC;
    }
    /* Go for the sequential CPU version */
    return PARSEC_HOOK_RETURN_NEXT;
}
END

BODY
{
    int tempmm = m == descA->mt-1 ? descA->m - m * descA->mb : descA->mb;
    int ldak = LDA(ddescA, T);
    int ldam = LDA(ddescA, C);

    CORE_ztrsm(dplasmaRight, dplasmaLower, dplasmaConjTrans, dplasmaNonUnit,
               tempmm, descA->nb,
               (dplasma_complex64_t)1.0, T /*A(k, k)*/, ldak,
                                         C /*A(m, k)*/, ldam);

    printlog("CORE_ztrsm( %d, %d )\n\t( %s, %s, %s, %s, %d, %d, %f, A(%d,%d)[%p], %d,  A(%d,%d)[%p], %d)\n",
             m, k,
             &dplasma_lapack_const( dplasmaRight ), &dplasma_lapack_const( dplasmaLower ),
             &dplasma_lapack_const( dplasmaConjTrans ), &dplasma_lapack_const( dplasmaNonUnit ),
             tempmm, descA->nb,
             1.0, k, k, T, ldak,
                  m, k, C, ldam);
}
END


/**************************************************
 *               potrf_zherk                      *
 **************************************************/
potrf_zherk(k, m) [high_priority = on
                   flops = inline_c %{ return FLOPS_ZHERK(CLEAN_MB(descA, m), descA->mb); %}
                   time_estimate = zherk_time_estimate]

// Execution space
k = 0   .. descA->mt-2
m = k+1 .. descA->mt-1

loc_A = %{ return LOC(descA, m, k); %}
loc_T = %{ return LOC(descA, m, m); %}

// Parallel partitioning
: descA(m, m)

//Parameters
READ  A <- C potrf_ztrsm(m, k)                [ type_remote = %{ return ADTT_DC(ddescA, loc_A, DEFAULT, TILED); %} ]
RW    T <- (k == 0)   ? ddescA(m, m)          [ type        = %{ return ADTT_READ(ddescA, loc_T, DEFAULT, TILED); %}
                                                type_data   = %{ return ADTT_READ(ddescA, loc_T, DEFAULT, LAPACK); %} ]
        <- (k != 0)   ? T potrf_zherk(k-1, m) [ type_remote = %{ return ADTT_DC(ddescA, loc_T, DEFAULT, TILED); %} ]
        -> (m == k+1) ? T potrf_zpotrf(m)  : T potrf_zherk(k+1, m) /* dep OUT: rely on datacopy dtt for sending */

; (m >= (descA->mt - PRI_CHANGE)) ? (descA->mt - m) * (descA->mt - m) * (descA->mt - m) + 3 * (m - k) : PRI_MAX

BODY [type=CUDA]
{
    int tempmm = m == descA->mt-1 ? descA->m - m*descA->mb : descA->mb;
    int ldam_A = LDA(ddescA, A);
    int ldam_T = LDA(ddescA, T);
    dplasma_cuda_handles_t *handles;
    double zone  =  1.;
    double mzone = -1.;
    cublasStatus_t status;

    handles = parsec_info_get(&gpu_stream->infos, cuda_handles_infokey);
    assert(NULL != handles);
    cublasSetStream( handles->cublas_handle, parsec_body.stream );
    status = cublasZherk_v2( handles->cublas_handle,
                             CUBLAS_FILL_MODE_LOWER, CUBLAS_OP_N,
                             tempmm, descA->mb,
                             &mzone, A, ldam_A,
                             &zone, T, ldam_T);
    PARSEC_CUDA_CHECK_ERROR( "cublasZherk_v2 ", status, {return PARSEC_HOOK_RETURN_ERROR;} );
}
END

BODY [type=HIP]
{
    int tempmm = m == descA->mt-1 ? descA->m - m*descA->mb : descA->mb;
    int ldam_A = LDA(ddescA, A);
    int ldam_T = LDA(ddescA, T);
    dplasma_hip_handles_t *handles;
    double zone  =  1.;
    double mzone = -1.;
    hipblasStatus_t status;

    handles = parsec_info_get(&gpu_stream->infos, hip_handles_infokey);
    assert(NULL != handles);
    status = hipblasZherk( handles->hipblas_handle,
                                  HIPBLAS_FILL_MODE_LOWER, HIPBLAS_OP_N,
                                  tempmm, descA->mb,
                                  &mzone, A, ldam_A,
                                  &zone, T, ldam_T);
    DPLASMA_HIPBLAS_CHECK_ERROR("hipblasZherk", status, {return PARSEC_HOOK_RETURN_ERROR;});
}
END

BODY [type=RECURSIVE]
{
    int tempmm = m == descA->mt-1 ? descA->m - m*descA->mb : descA->mb;

    if ( (tempmm > smallnb) || (descA->nb > smallnb) )
    {
        subtile_desc_t *small_descT;
        subtile_desc_t *small_descA;
        parsec_taskpool_t* parsec_zherk;

        small_descT = subtile_desc_create( descA, m, m,
                                           smallnb, smallnb, 0, 0, tempmm, tempmm );
        small_descT->mat = T;

        small_descA = subtile_desc_create( descA, m, k,
                                           smallnb, smallnb, 0, 0, tempmm, descA->nb );
        small_descA->mat = A;

        parsec_zherk = dplasma_zherk_New( dplasmaLower, dplasmaNoTrans,
                                         (double)-1.0, (parsec_tiled_matrix_t*) small_descA,
                                         (double)1.0,  (parsec_tiled_matrix_t*) small_descT);

        parsec_recursivecall((parsec_task_t*)this_task,
                             parsec_zherk, zherk_recursive_cb,
                             2, small_descA, small_descT);
        return PARSEC_HOOK_RETURN_ASYNC;
    }
    /* Go for the sequential CPU version */
    return PARSEC_HOOK_RETURN_NEXT;
}
END

BODY
{
    int tempmm = m == descA->mt-1 ? descA->m - m*descA->mb : descA->mb;
    int ldam_A = LDA(ddescA, A);
    int ldam_T = LDA(ddescA, T);

    CORE_zherk(dplasmaLower, dplasmaNoTrans,
               tempmm, descA->mb,
               (double)-1.0, A /*A(m, k)*/, ldam_A,
               (double) 1.0, T /*A(m, m)*/, ldam_T);
    printlog("CORE_zherk( %d, %d )\n\t( %s, %s, %d, %d, %f, A(%d,%d)[%p], %d, %f, A(%d,%d)[%p], %d)\n",
             k, m,
             &dplasma_lapack_const( dplasmaLower ), &dplasma_lapack_const( dplasmaNoTrans ),
             tempmm, descA->mb,
             -1.0, m, k, A, ldam_A,
              1.0, m, m, T, ldam_T);
}
END

/**************************************************
 *               potrf_zgemm                      *
 **************************************************/
// Name
potrf_zgemm(m, n, k) [flops = inline_c %{ return FLOPS_ZGEMM(CLEAN_MB(descA, m), descA->mb, descA->mb); %}
                      time_estimate = zgemm_time_estimate]

// Execution space
k = 0   .. descA->mt-3
m = k+2 .. descA->mt-1
n = k+1 .. m-1

loc_A = %{ return LOC(descA, m, k); %}
loc_B = %{ return LOC(descA, n, k); %}
loc_C = %{ return LOC(descA, m, n); %}

// Parallel partitioning
: descA(m, n)

// Parameters
READ  A <- C potrf_ztrsm(m, k)                   [ type_remote = %{ return ADTT_DC(ddescA, loc_A, DEFAULT, TILED); %} ]
READ  B <- C potrf_ztrsm(n, k)                   [ type_remote = %{ return ADTT_DC(ddescA, loc_B, DEFAULT, TILED); %} ]
RW    C <- (k == 0)   ? ddescA(m, n)             [ type        = %{ return ADTT_READ(ddescA, loc_C, DEFAULT, TILED); %}
                                                   type_data   = %{ return ADTT_READ(ddescA, loc_C, DEFAULT, LAPACK); %} ]
        <- (k != 0)   ? C potrf_zgemm(m, n, k-1) [ type_remote = %{ return ADTT_DC(ddescA, loc_C, DEFAULT, TILED); %} ]
        -> (n == k+1) ? C potrf_ztrsm(m, n) : C potrf_zgemm(m, n, k+1) /* dep OUT: rely on datacopy dtt for sending */

; (m >= (descA->mt - PRI_CHANGE)) ? (descA->mt - m) * (descA->mt - m) * (descA->mt - m) + 3 * ((2 * descA->mt) - m - n - 3) * (m - n) + 6 * (m - k) : PRI_MAX

BODY [type=CUDA
      A.size=%{ return descA->mb*descA->nb*parsec_datadist_getsizeoftype(descA->mtype);%}
      B.size=%{ return descA->mb*descA->nb*parsec_datadist_getsizeoftype(descA->mtype);%}
      C.size=%{ return descA->mb*descA->nb*parsec_datadist_getsizeoftype(descA->mtype);%}
      A.dc=ddescA B.dc=ddescA C.dc=ddescA
      stage_in=dplasma_cuda_lapack_stage_in
      stage_out=dplasma_cuda_lapack_stage_out]
{
#if defined(PRECISION_z) || defined(PRECISION_c)
    cuDoubleComplex zone  = make_cuDoubleComplex( 1., 0.);
    cuDoubleComplex mzone = make_cuDoubleComplex(-1., 0.);
#else
    double zone  =  1.;
    double mzone = -1.;
#endif
    int tempmm = m == descA->mt-1 ? descA->m - m * descA->mb : descA->mb;
    int ldam_A = LDA(ddescA, A);
    int ldan_B = LDA(ddescA, B);
    int ldam_C = LDA(ddescA, C);
    assert( ldam_A <= descA->mb );
    assert( ldan_B <= descA->mb );
    assert( ldam_C <= descA->mb );

    cublasStatus_t status;
    dplasma_cuda_handles_t *handles;
    handles = parsec_info_get(&gpu_stream->infos, cuda_handles_infokey);
    assert(NULL != handles);

    cublasSetStream( handles->cublas_handle, parsec_body.stream );
    status = cublasZgemm_v2( handles->cublas_handle,
                             CUBLAS_OP_N, CUBLAS_OP_C,
                             tempmm, descA->mb, descA->mb,
                             &mzone, (cuDoubleComplex*)A, ldam_A,
                                     (cuDoubleComplex*)B, ldan_B,
                             &zone,  (cuDoubleComplex*)C, ldam_C );
    PARSEC_CUDA_CHECK_ERROR( "cublasZgemm_v2 ", status, {return PARSEC_HOOK_RETURN_ERROR;} );
}
END

BODY [type=HIP
      A.size=%{ return descA->mb*descA->nb*parsec_datadist_getsizeoftype(descA->mtype);%}
      B.size=%{ return descA->mb*descA->nb*parsec_datadist_getsizeoftype(descA->mtype);%}
      C.size=%{ return descA->mb*descA->nb*parsec_datadist_getsizeoftype(descA->mtype);%}
      A.dc=ddescA B.dc=ddescA C.dc=ddescA
      stage_in=dplasma_hip_lapack_stage_in
      stage_out=dplasma_hip_lapack_stage_out]
{
#if defined(PRECISION_z) || defined(PRECISION_c)
    hipblasDoubleComplex zone  = {  1., 0. };
    hipblasDoubleComplex mzone = { -1., 0. };
#else
    double zone  =  1.;
    double mzone = -1.;
#endif
    int tempmm = m == descA->mt-1 ? descA->m - m * descA->mb : descA->mb;
    int ldam_A = LDA(ddescA, A);
    int ldan_B = LDA(ddescA, B);
    int ldam_C = LDA(ddescA, C);
    assert( ldam_A <= descA->mb );
    assert( ldan_B <= descA->mb );
    assert( ldam_C <= descA->mb );

    hipblasStatus_t status;
    dplasma_hip_handles_t *handles;
    handles = parsec_info_get(&gpu_stream->infos, hip_handles_infokey);
    assert(NULL != handles);
    status = hipblasZgemm( handles->hipblas_handle,
                                  HIPBLAS_OP_N, HIPBLAS_OP_C,
                                  tempmm, descA->mb, descA->mb,
                                  &mzone, A, ldam_A,
                                          B, ldan_B,
                                  &zone,  C, ldam_C );
    DPLASMA_HIPBLAS_CHECK_ERROR("hipblasZgemm", status, {return PARSEC_HOOK_RETURN_ERROR;});
}
END

BODY [type=RECURSIVE]
{
    int tempmm = m == descA->mt-1 ? descA->m - m * descA->mb : descA->mb;

    if ( (tempmm > smallnb) || (descA->nb > smallnb) )
    {
        subtile_desc_t *small_descA;
        subtile_desc_t *small_descB;
        subtile_desc_t *small_descC;
        parsec_taskpool_t *parsec_zgemm;

        small_descA = subtile_desc_create( descA, m, k,
                                           smallnb, smallnb, 0, 0, tempmm, descA->nb );
        small_descA->mat = A;

        small_descB = subtile_desc_create( descA, n, k,
                                           smallnb, smallnb, 0, 0, descA->mb, descA->nb );
        small_descB->mat = B;

        small_descC = subtile_desc_create( descA, m, n,
                                           smallnb, smallnb, 0, 0, tempmm, descA->nb );
        small_descC->mat = C;

        parsec_zgemm = dplasma_zgemm_New(dplasmaNoTrans, dplasmaConjTrans,
                                        (dplasma_complex64_t)-1.0,
                                        (parsec_tiled_matrix_t *)small_descA,
                                        (parsec_tiled_matrix_t *)small_descB,
                                        (dplasma_complex64_t) 1.0,
                                        (parsec_tiled_matrix_t *)small_descC);

        parsec_recursivecall((parsec_task_t*)this_task,
                             parsec_zgemm, zgemm_recursive_cb,
                             3, small_descA, small_descB, small_descC );

        return PARSEC_HOOK_RETURN_ASYNC;
    }
    /* Go to CPU sequential kernel */
    return PARSEC_HOOK_RETURN_NEXT;
}
END

BODY
{
    int tempmm = m == descA->mt-1 ? descA->m - m * descA->mb : descA->mb;
    int ldam_A = LDA(ddescA, A);
    int ldan_B = LDA(ddescA, B);
    int ldam_C = LDA(ddescA, C);

    CORE_zgemm(dplasmaNoTrans, dplasmaConjTrans,
               tempmm, descA->mb, descA->mb,
               (dplasma_complex64_t)-1.0, A /*A(m, k)*/, ldam_A,
                                          B /*A(n, k)*/, ldan_B,
               (dplasma_complex64_t) 1.0, C /*A(m, n)*/, ldam_C);

    printlog("CORE_zgemm( %d, %d, %d )\n\t( %s, %s, %d, %d, %d, %f, A(%d,%d)[%p], %d, A(%d,%d)[%p], %d, %f, A(%d,%d)[%p], %d)\n",
             m, n, k,
             &dplasma_lapack_const( dplasmaNoTrans ),  &dplasma_lapack_const( dplasmaConjTrans ),
             tempmm, descA->mb, descA->mb,
             -1.0, m, k, A, ldam_A,
                   n, k, B, ldan_B,
              1.0, m, n, C, ldam_C);
}
END

extern "C" %{

/* Compute the time estimates based on device capabilities and flops for the task */
static int64_t zpotrf_time_estimate(const parsec_task_t *task, parsec_device_module_t *dev) {
    int mb = ((parsec_zpotrf_L_taskpool_t*)task->taskpool)->_g_descA->mb;
    return (int64_t)FLOPS_ZPOTRF(mb) / dev->gflops_fp64;
}
static int64_t ztrsm_time_estimate(const parsec_task_t *task, parsec_device_module_t *dev) {
    int mb = ((parsec_zpotrf_L_taskpool_t*)task->taskpool)->_g_descA->mb;
    return (int64_t)FLOPS_ZTRSM(PlasmaRight, mb, mb) / dev->gflops_fp64;
}
static int64_t zherk_time_estimate(const parsec_task_t *task, parsec_device_module_t *dev) {
    int mb = ((parsec_zpotrf_L_taskpool_t*)task->taskpool)->_g_descA->mb;
    return (int64_t)FLOPS_ZHERK(mb, mb) / dev->gflops_fp64;
}
static int64_t zgemm_time_estimate(const parsec_task_t *task, parsec_device_module_t *dev) {
    int mb = ((parsec_zpotrf_L_taskpool_t*)task->taskpool)->_g_descA->mb;
    return (int64_t)FLOPS_ZGEMM(mb, mb, mb) / dev->gflops_fp64;
}

#if defined(PARSEC_HAVE_DEV_RECURSIVE_SUPPORT)
/*
 * A function to recursively update the value of the INFO argument for
 * recursive calls. We need a special function because the recursive calls being asynchronous
 * will be completed by another thread at a later date. This means we cannot use the stack of
 * the thread creating the recursive algorithm to store any temporary value (such as INFO).
 * We are therefore forced to create a local variable on the task, and use it as the INFO
 * for the recursive calls.
 *
 * As we are handling the diagonal tiles recursively, we have to scale the INFO in case of errors
 * to reflect the position in the global matrix and not on the current tile.
 */
static void zpotrf_recursive_cb(parsec_taskpool_t* tp, const parsec_recursive_callback_t* data)
{
    parsec_zpotrf_L_taskpool_t* tppo = (parsec_zpotrf_L_taskpool_t*)tp;
    __parsec_zpotrf_L_potrf_zpotrf_task_t* task = (__parsec_zpotrf_L_potrf_zpotrf_task_t*)data->task;

    if( (0 < task->locals.info.value) && (0 == *tppo->_g_INFO) ) {
        /* we need to scale the INFO according to the parent taskpool tile size */
        *tppo->_g_INFO = task->locals.info.value + task->locals.k.value * ((parsec_zpotrf_L_taskpool_t*)task->taskpool)->_g_descA->nb;
    }
    dplasma_zpotrf_Destruct(tp);
}
static void zgemm_recursive_cb(parsec_taskpool_t* tp, const parsec_recursive_callback_t* data) {
    (void)data;
    dplasma_zgemm_Destruct(tp);
}
static void zherk_recursive_cb(parsec_taskpool_t* tp, const parsec_recursive_callback_t* data) {
    (void)data;
    dplasma_zherk_Destruct(tp);
}
static void ztrsm_recursive_cb(parsec_taskpool_t* tp, const parsec_recursive_callback_t* data) {
    (void)data;
    dplasma_ztrsm_Destruct(tp);
}
#endif /* PARSEC_HAVE_DEV_RECURSIVE_SUPPORT */
%}

